{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "689bc3ab-aa4b-493a-ae90-b19b8e1f64d6",
   "metadata": {},
   "source": [
    "# Turning Raw Spotify Track Data into a Modeling Dataset  \n",
    "*Integration, cleaning, and feature preparation for popularity prediction*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee09e004-856f-44de-bdec-83cda3dc8b1d",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "Music streaming has become an ordinary part of daily life, and platforms like Spotify play a central role in how listeners discover and engage with music. The listening experience today is far more personalized than it was in the past, shaped by recommendations that adapt to individual tastes, habits, and patterns over time. At the core of this transformation is data.\n",
    "\n",
    "While listener data is not available in this project, Spotify provides extensive information at the track and artist level. This includes audio features that describe how a song sounds, metadata that situates it in time and context, and aggregate measures of engagement such as track popularity. Together, these features offer a partial but meaningful view into how songs are represented and surfaced on the platform.\n",
    "\n",
    "This notebook focuses on preparing and integrating Spotify track and artist datasets into a clean, modeling ready format. The resulting dataset serves as the foundation for subsequent exploratory analysis and predictive modeling of song popularity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceb4ef1-d3e4-4bf5-8950-12729628f3d1",
   "metadata": {},
   "source": [
    "## 2. Libraries and Setup\n",
    "This notebook uses standard Python libraries for data manipulation and preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90782aea-6d83-4b3d-b0f8-5d52ec70c9ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T22:34:46.298814Z",
     "iopub.status.busy": "2026-01-25T22:34:46.298414Z",
     "iopub.status.idle": "2026-01-25T22:34:46.642154Z",
     "shell.execute_reply": "2026-01-25T22:34:46.641537Z",
     "shell.execute_reply.started": "2026-01-25T22:34:46.298799Z"
    }
   },
   "outputs": [],
   "source": [
    "# Core utilities\n",
    "from __future__ import annotations\n",
    "# Enables postponed evaluation of type annotations for cleaner type hints and forward compatibility.\n",
    "\n",
    "import ast\n",
    "# Used to safely convert list-like strings in the raw Spotify data into actual Python lists.\n",
    "\n",
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Text processing\n",
    "import re\n",
    "\n",
    "\n",
    "# Display settings\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f259d8-4c5c-47b7-ad13-35fd441b1fea",
   "metadata": {},
   "source": [
    "## 3. Data Wrangling and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e4454d4-f9cf-40ee-bac6-1d6143e230e6",
   "metadata": {},
   "source": [
    "### 3.1 Read Files\n",
    "The data preparation process begins by loading the raw Spotify track and artist datasets. These datasets are later combined and transformed to produce an enriched, track-level dataset that is saved as a parquet file for downstream exploratory analysis and modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e423787-91ea-4504-816a-0014aab80c3a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-25T22:34:46.643963Z",
     "iopub.status.busy": "2026-01-25T22:34:46.643418Z"
    }
   },
   "outputs": [],
   "source": [
    "tracks = pd.read_parquet(\"tracks.parquet\")\n",
    "artists = pd.read_csv(\"artists.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80782dff-ca1a-4391-a933-088a0b1dd12d",
   "metadata": {},
   "source": [
    "### 3.2 Data Cleaning and Standardization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2e4bb95-5236-4da7-a2cc-dbbf1b141c1b",
   "metadata": {},
   "source": [
    "#### 3.2.1 Handling Missing Values\n",
    "This section outlines the approach used to address missing values in the Spotify track and artist datasets. Handling missing data is an important part of preparing a reliable analytical dataset, as it helps ensure consistency and reduces the risk of introducing noise during later stages of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db592af-363d-478d-9a87-78421d4555b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_dfs_dict = {\"tracks\": tracks,\n",
    "               \"artists\": artists}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81758c7d-c8f7-4194-90c4-7b77b34cce82",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_null_summary(dataset_dict):\n",
    "    \"\"\"\n",
    "    Create a dataset-level overview of size and missing values.\n",
    "    \"\"\"\n",
    "    null_list = []\n",
    "    for name, df in dataset_dict.items():\n",
    "        n_rows = df.shape[0]\n",
    "        n_cols = df.shape[1]\n",
    "        null_sum = df.isna().any(axis=1).sum()\n",
    "        total_cells = n_rows * n_cols\n",
    "        # get list of column names with null values\n",
    "        null_columns = df.columns[df.isnull().any()].tolist()\n",
    "        # get number of columns with null values \n",
    "        n_null_columns = len(null_columns)\n",
    "        # if no null columns, return an empty string\n",
    "        null_columns_str = ', '.join(null_columns) if null_columns else \"\"\n",
    "        null_list.append({\n",
    "                         \"dataframe\":name,\n",
    "                         \"n_rows\":n_rows,\n",
    "                         \"n_cols\": n_cols,\n",
    "                         \"rows_with_nulls\":null_sum,\n",
    "                         \"pct_rows_with_nulls\": round((null_sum / n_rows * 100) if n_rows else 0, 3),\n",
    "                         \"columns_with_nulls\":n_null_columns,\n",
    "                         \"null_columns_names\":null_columns_str})\n",
    "    return pd.DataFrame(null_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f30d251-396b-4682-a47c-28f4eb15d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df = create_null_summary(all_dfs_dict).sort_values(\n",
    "    by=\"pct_rows_with_nulls\",\n",
    "    ascending=False\n",
    ")\n",
    "null_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb897f13-95fa-4b39-ad8a-bf02222f0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop nulls\n",
    "tracks = tracks.dropna()\n",
    "artists = artists.dropna()\n",
    "\n",
    "# Sanity Check\n",
    "tracks.isna().sum().sum(), artists.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4836fb2c-0998-478a-af9f-614c978c4c5f",
   "metadata": {},
   "source": [
    "This initial overview provides a quick check of data completeness across both datasets. The number of missing values is extremely small relative to the overall size of the data, so those records are removed to keep the dataset clean. With missing values addressed, the next step focuses on reviewing and standardizing data types before continuing with further preparation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241e2fe9-d932-4f43-be31-1f32e34b3e2f",
   "metadata": {},
   "source": [
    "#### 3.2.2 Data Type Standardization\n",
    "This section focuses on reviewing and standardizing data types across the track and artist datasets. Ensuring that variables are stored using appropriate data types is a key step in data preparation, as it supports accurate transformations, comparisons, and downstream analysis. An initial inspection of each dataset is performed to confirm that columns align with their expected representations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0773c0-c22b-4e0b-97c1-8c4965ce1347",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc54be05-f6a4-42e3-9afb-d6983008fbe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896f6e5b-73ab-43a7-ba0c-77d97261ba93",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a08f6a0d-2c3f-4659-80d9-151f41ad8767",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "924c6387-882e-47c0-bbe9-f73d2edec0ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_specifications = {\n",
    "    \"float\": [\n",
    "        \"danceability\",\n",
    "        \"energy\",\n",
    "        \"loudness\",\n",
    "        \"speechiness\",\n",
    "        \"acousticness\",\n",
    "        \"instrumentalness\",\n",
    "        \"liveness\",\n",
    "        \"valence\",\n",
    "        \"tempo\",\n",
    "        \"followers\"\n",
    "    ],\n",
    "    \"int\": [\n",
    "        \"popularity\",\n",
    "        \"duration_ms\",\n",
    "        \"key\",\n",
    "        \"mode\",\n",
    "        \"time_signature\"\n",
    "    ],\n",
    "    \"string\": [\n",
    "        \"id\",\n",
    "        \"name\",\n",
    "        \"release_date\"\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136cf277-483e-401f-a0c3-1b8dbae018a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_dtypes(df, spec, errors=\"coerce\"):\n",
    "    \"\"\"\n",
    "    Standardize dataframe dtypes based on a spec dict.\n",
    "    - Preserves missing values using pandas nullable dtypes where appropriate.\n",
    "    - Ignores columns not present in the dataframe.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # dates\n",
    "    for col in spec.get(\"datetime\", []):\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_datetime(df[col], errors=errors)\n",
    "\n",
    "    # floats\n",
    "    for col in spec.get(\"float\", []):\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "\n",
    "    # integers\n",
    "    for col in spec.get(\"int\", []):\n",
    "        if col in df.columns:\n",
    "            df[col] = pd.to_numeric(df[col], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "    # strings\n",
    "    for col in spec.get(\"string\", []):\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(\"string\")\n",
    "\n",
    "    # categories\n",
    "    for col in spec.get(\"category\", []):\n",
    "        if col in df.columns:\n",
    "            df[col] = df[col].astype(\"category\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f22c6b1-4ec3-465c-b971-54deb84c8e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists = standardize_dtypes(artists, dtype_specifications)\n",
    "tracks = standardize_dtypes(tracks, dtype_specifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e40f455-4350-4840-8139-388f79994bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract release year for modeling\n",
    "tracks[\"release_year\"] = tracks[\"release_date\"].str.slice(0, 4).astype(\"Int64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26bbc9e-b63d-4a99-87f9-9b9e0eb6ecae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(artists.dtypes.sort_index())\n",
    "print(\"-----\" * 7)\n",
    "print(tracks.dtypes.sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3348cf-c1a8-4840-9b30-8753fb46ef5f",
   "metadata": {},
   "source": [
    "Data types were standardized where appropriate, while certain fields were intentionally left unchanged to support downstream transformations and modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09f0f0a9-d7d1-4a5a-8268-2a45baf14beb",
   "metadata": {},
   "source": [
    "#### 3.2.3 Duplicate Handling\n",
    "Duplicate checks are performed before parsing list-like fields to keep identifiers in a hashable format and avoid issues with row-level comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70cf9ac-e345-45bd-bad8-00e6c4d7455c",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_duplicate_track_id = tracks.duplicated(subset='id')\n",
    "print(is_duplicate_track_id.sum())\n",
    "\n",
    "is_duplicate_artist_id = artists.duplicated(subset='id')\n",
    "print(is_duplicate_artist_id.sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76831a00-88a6-449a-b85f-0cd94bd5e587",
   "metadata": {},
   "source": [
    "Duplicate checks were performed using the unique identifier columns for both tracks and artists. No duplicate IDs were identified at the raw dataset level, confirming that each track and artist is uniquely represented prior to downstream joins and feature aggregation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78b610d-2ab4-4977-a6bf-0c10977bf474",
   "metadata": {},
   "source": [
    "#### 3.2.4 Handling Outliers\n",
    "This section reviews potential outliers across numeric variables using a custom function that identifies extreme values on a colum-level basis and summarizes them by proportion. This approach helps prioritize which variables warrant closer inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a156af-1a24-410c-a920-949e96aad3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_outliers_iqr(df):\n",
    "    \"\"\"\n",
    "    Computes the proportion of IQR-based outliers in each numeric column\n",
    "    to highlight variables with heavy-tailed distributions.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for col in df.select_dtypes(include=[\"number\"]).columns:\n",
    "        s = df[col].dropna()\n",
    "        if s.empty:\n",
    "            continue\n",
    "\n",
    "        q1 = s.quantile(0.25)\n",
    "        q3 = s.quantile(0.75)\n",
    "        iqr = q3 - q1\n",
    "\n",
    "        if iqr == 0:\n",
    "            outlier_count = 0\n",
    "        else:\n",
    "            lower = q1 - 1.5 * iqr\n",
    "            upper = q3 + 1.5 * iqr\n",
    "            outlier_count = ((s < lower) | (s > upper)).sum()\n",
    "\n",
    "        rows.append({\n",
    "            \"Column\": col,\n",
    "            \"Outlier_%\": outlier_count / len(s) * 100\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143280ac-7e6c-42e6-94de-280b309a12b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "outlier_reports = {}\n",
    "\n",
    "outlier_reports[\"artists\"] = detect_outliers_iqr(artists)\n",
    "outlier_reports[\"tracks\"] = detect_outliers_iqr(tracks)\n",
    "\n",
    "combined_outliers = (\n",
    "    pd.concat(outlier_reports, names=[\"Dataset\"])\n",
    "      .reset_index(level=0)\n",
    "      .rename(columns={\"level_0\": \"Dataset\"})\n",
    ")\n",
    "\n",
    "# Sort\n",
    "combined_outliers = combined_outliers.sort_values(\n",
    "    \"Outlier_%\",\n",
    "    ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "# Stylize\n",
    "styled_outliers = (\n",
    "    combined_outliers.style\n",
    "    .format({\"Outlier_%\": \"{:.2f}%\"})\n",
    "    .background_gradient(axis=0,\n",
    "                         gmap = combined_outliers[\"Outlier_%\"],\n",
    "                         cmap=\"YlOrRd\"\n",
    "                        )\n",
    ")\n",
    "\n",
    "styled_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb86af2-e780-44ac-b7ea-c80484a3028b",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists[[\"followers\", \"popularity\"]].describe(percentiles=[0.01, 0.05, 0.5, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1833c4f-5034-4648-8b0f-054424c6ab92",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.sort_values(\"followers\", ascending=False).head(10)[\n",
    "    [\"name\", \"followers\", \"popularity\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ac0936-f9a6-477e-b042-ce06ccfc46ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "artists.sort_values(\"followers\", ascending=True).head(10)[\n",
    "    [\"name\", \"followers\", \"popularity\"]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a022611b-2a0a-4571-a678-b286b6cbed00",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(artists[\"followers\"], bins=100)\n",
    "plt.yscale(\"log\")\n",
    "plt.title(\"Artist Followers (log scale)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b40fb61d-f389-4fdc-aaad-cf0326b131b8",
   "metadata": {},
   "source": [
    "Several audio features, such as instrumentalness, are known to exhibit highly skewed distributions due to the wide variety of musical styles represented in the dataset. These patterns are expected and do not indicate data quality issues, so no additional action was taken for those variables.\n",
    "\n",
    "Artist-level metrics, including popularity and follower counts, were reviewed as a sanity check to ensure extreme values were plausible. Highly followed, well-known artists appeared at the upper end of the distribution, while lesser-known artists with zero or low follower counts appeared at the lower end, consistent with real-world expectations. As a result, no values were capped or removed during this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284a972-abcc-4209-9a70-99abad0429fc",
   "metadata": {},
   "source": [
    "#### 3.2.5 Rename Columns\n",
    "This section standardizes column names across datasets to reduce ambiguity and improve clarity prior to merging. Several fields share common names across tables, such as identifiers and popularity metrics, which can lead to confusion during joins and downstream analysis if left unchanged. Renaming these columns early helps make dataset roles explicit and ensures that merged features remain interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a815d407-4e99-49b7-bd09-31a810cf4095",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.rename(columns={\n",
    "    \"id\": \"track_id\",\n",
    "    \"name\": \"track_name\",\n",
    "    \"popularity\": \"track_popularity\",\n",
    "    \"id_artists\": \"artist_id_list\"\n",
    "}, \n",
    "              inplace = True)\n",
    "\n",
    "artists.rename(columns={\n",
    "    \"id\": \"artist_id\",\n",
    "    \"name\": \"artist_name\",\n",
    "    \"popularity\": \"artist_popularity\"\n",
    "}, \n",
    "              inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755db6a4-d392-415a-96c8-383a41adb015",
   "metadata": {},
   "source": [
    "After renaming overlapping columns to clearly distinguish track-level and artist-level attributes, the datasets are better structured for subsequent merges. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d185c123-e688-48b0-a71c-1c45d2a2e62f",
   "metadata": {},
   "source": [
    "#### 3.2.6 Normalizing and Parsing List-Like Fields\n",
    "Some fields in the raw data represent multi-value relationships. Before expanding the data into a track–artist format and performing merges, these fields were standardized so that list-like values are consistently represented as flat Python lists. This reduces ambiguity during downstream joins and ensures that later aggregation steps behave consistently."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "157da029-bfad-41c8-8f28-aa6b6b8976aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_list_like(x):\n",
    "    \"\"\"\n",
    "    Convert stringified Python lists into real lists.\n",
    "    Returns the original value if it is already a list or cannot be parsed.\n",
    "    \"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return x\n",
    "    if pd.isna(x):\n",
    "        return x\n",
    "    if isinstance(x, str) and x.startswith(\"[\") and x.endswith(\"]\"):\n",
    "        try:\n",
    "            val = ast.literal_eval(x)\n",
    "            return val if isinstance(val, list) else x\n",
    "        except Exception:\n",
    "            return x\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a78a8f-1898-4051-a5a5-e1c1e82b01f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks[\"artists\"] = tracks[\"artists\"].apply(parse_list_like)\n",
    "tracks[\"artist_id_list\"] = tracks[\"artist_id_list\"].apply(parse_list_like)\n",
    "artists[\"genres\"] = artists[\"genres\"].apply(parse_list_like)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f12c37e-ab5f-4a81-93cc-81e7bac469fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_artist_id_list(artist_id_list):\n",
    "    \"\"\"\n",
    "    Normalize artist_id_list into a flat Python list of clean artist ID strings.\n",
    "    Safe against NaN, strings, lists, and numpy arrays.\n",
    "    \"\"\"\n",
    "\n",
    "    # Handle None\n",
    "    if artist_id_list is None:\n",
    "        return []\n",
    "\n",
    "    # Handle scalar NaN \n",
    "    if isinstance(artist_id_list, (float, np.floating)) and pd.isna(artist_id_list):\n",
    "        return []\n",
    "\n",
    "    # If numpy array, convert to list\n",
    "    if isinstance(artist_id_list, np.ndarray):\n",
    "        artist_id_list = artist_id_list.tolist()\n",
    "\n",
    "    # String: parse list-like strings or wrap single value\n",
    "    if isinstance(artist_id_list, str):\n",
    "        s = artist_id_list.strip()\n",
    "        if s.startswith(\"[\") and s.endswith(\"]\"):\n",
    "            try:\n",
    "                artist_id_list = ast.literal_eval(s)\n",
    "            except Exception:\n",
    "                return [s.strip().strip(\"'\\\"\")]\n",
    "        else:\n",
    "            return [s.strip().strip(\"'\\\"\")]\n",
    "\n",
    "    # Wrap non-list scalars\n",
    "    if not isinstance(artist_id_list, list):\n",
    "        return [str(artist_id_list).strip().strip(\"'\\\"\")]\n",
    "\n",
    "    # Flatten one level if list-of-lists\n",
    "    flattened = []\n",
    "    for item in artist_id_list:\n",
    "        if isinstance(item, list):\n",
    "            flattened.extend(item)\n",
    "        else:\n",
    "            flattened.append(item)\n",
    "\n",
    "    # Clean \n",
    "    cleaned = []\n",
    "    for item in flattened:\n",
    "        if item is None:\n",
    "            continue\n",
    "        if isinstance(item, (float, np.floating)) and pd.isna(item):\n",
    "            continue\n",
    "        item_str = str(item).strip().strip(\"'\\\"\")\n",
    "        if item_str:\n",
    "            cleaned.append(item_str)\n",
    "\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0afb4b-2ba3-4a9b-849a-c50cf6a6bc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks = tracks.copy()\n",
    "\n",
    "tracks[\"artist_id_list\"] = tracks[\"artist_id_list\"].apply(normalize_artist_id_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4799d564-5a47-4a60-9fb1-7f59ef49030a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "After parsing, artist and genre information is explicitly represented as structured lists rather than raw strings. This makes multi-artist relationships transparent and prepares the data for subsequent aggregation without altering the underlying unit of analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02aefa63-db11-4bd4-b1d1-d3912bb6f393",
   "metadata": {},
   "source": [
    "### 3.3 Dataset Integration \n",
    "Some tracks in the dataset are associated with multiple artists, while artist-level information is stored separately. To incorporate artist information without altering the original tracks dataset, the data is temporarily reshaped into a track–artist format, enriched with artist metadata, and then summarized back to the track level. The result is a new dataset that combines track features with aggregated artist information for downstream modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698812bf-166f-401c-bc67-aae2c71f904e",
   "metadata": {},
   "source": [
    "#### 3.3.1 Expanding Tracks into a Long Track-Artist Table\n",
    "Some tracks are associated with multiple artists. In this step, the data is expanded so that each row represents a single track–artist relationship. This intermediate table allows artist-level information to be joined correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78756ad7-0e0a-44e4-8cdd-05d6edfe5af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_artist_long = (\n",
    "    tracks[[\"track_id\", \"artist_id_list\"]]\n",
    "    .explode(\"artist_id_list\", ignore_index=True)\n",
    "    .rename(columns={\"artist_id_list\": \"artist_id\"})\n",
    ")\n",
    "\n",
    "# Composite key \n",
    "track_artist_long[\"track_artist_id\"] = (\n",
    "    track_artist_long[\"track_id\"].astype(str) + \"_\" +\n",
    "    track_artist_long[\"artist_id\"].astype(str)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde528a7-3098-4f17-9dc9-a0296ad46e5a",
   "metadata": {},
   "source": [
    "#### 3.3.2 Adding Artist Information to the Long Track-Artist Table\n",
    "Artist-level attributes such as popularity, follower counts, genres, and artist names are merged into the track–artist table created in the previous step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30df7ff3-0430-421d-adf5-9c4d64967aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge tracks with artist information \n",
    "track_artist_long = track_artist_long.merge(\n",
    "    artists[[\"artist_id\",\"artist_name\",\"genres\", \"artist_popularity\", \"followers\"]],\n",
    "    on=\"artist_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "track_artist_long[\"n_genres\"] = track_artist_long[\"genres\"].apply(\n",
    "    lambda g: len(g) if isinstance(g, list) else 0\n",
    ")\n",
    "track_artist_long.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5bae5e-ad17-488d-a957-b0394a8ce5e7",
   "metadata": {},
   "source": [
    "#### 3.3.3 Creating Track-Level Artist Features\n",
    "Artist-level information is then summarized back to the track level. This includes features such as the number of artists on a track and aggregated artist popularity and follower metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3501819-8894-47a5-aba4-210a5f4f9e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_agg = (\n",
    "    track_artist_long\n",
    "    .groupby(\"track_id\", as_index=False)\n",
    "    .agg(\n",
    "        artist_popularity_mean=(\"artist_popularity\", \"mean\"),\n",
    "        artist_popularity_max=(\"artist_popularity\", \"max\"),\n",
    "        artist_followers_mean=(\"followers\", \"mean\"),\n",
    "        artist_followers_max=(\"followers\", \"max\"),\n",
    "        n_artists=(\"artist_id\", \"nunique\"), \n",
    "        artist_genres_mean = (\"n_genres\", \"mean\"),\n",
    "        artist_genres_max = (\"n_genres\", \"max\"),\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866d5f30-58c7-418b-a527-e413b1f86f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45a9989-7910-4d5c-9e8a-671786bbf7b9",
   "metadata": {},
   "source": [
    "#### 3.3.4 Creating an Enriched Tracks Dataset\n",
    "The aggregated artist features are joined to the original track data to form a new, enriched tracks dataset, while preserving the original tracks table for independent analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39733fc-66f3-44e7-ba1b-969a7a017427",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_enriched = tracks.merge(\n",
    "    artist_agg,\n",
    "    on=\"track_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "tracks_enriched.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b6fd2ce-d6da-4600-bda8-e26833498db5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_enriched.isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26afb7da-743c-451c-a59c-23938d9f3700",
   "metadata": {},
   "outputs": [],
   "source": [
    "artist_agg_cols = [\n",
    "    \"artist_followers_mean\",\n",
    "    \"artist_followers_max\",\n",
    "    \"artist_popularity_mean\",\n",
    "    \"artist_popularity_max\"\n",
    "]\n",
    "\n",
    "tracks_enriched_model = tracks_enriched.dropna(subset=artist_agg_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e3389d-5a48-41a3-a3c9-1b9cba7d6f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_enriched_model.isna().mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18809741-c4fa-45c3-a659-2afd77e3493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = \"tracks_enriched_model.parquet\"\n",
    "\n",
    "tracks_enriched_model.to_parquet(output_path, index=False)\n",
    "\n",
    "print(f\"Enriched dataset successfully saved to '{output_path}'.\")\n",
    "print(f\"Final shape: {tracks_enriched_model.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710afba4-54a1-4c31-9a63-d5c667e4b523",
   "metadata": {},
   "source": [
    "A small number of tracks lacked aggregated artist metadata. Because this represented a minimal portion of the data and was limited to artist-derived features, these rows were excluded from the modeling dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dc3390-5621-4255-a6ec-ae20fa569428",
   "metadata": {},
   "source": [
    "## 4. Data Preparation Summary and Key Takeaways\n",
    "**Summary**\n",
    "\n",
    "This notebook focused on cleaning and preparing Spotify track and artist data for analysis. The raw data included track-level audio features and artist-level metadata, with some tracks linked to multiple artists.\n",
    "\n",
    "To handle this, tracks were temporarily expanded to a track–artist format so artist information could be added correctly. Artist features were then summarized back to the track level to create a new enriched dataset.\n",
    "\n",
    "**Key Takeaways**\n",
    "* Track and artist data exist at different levels and required reshaping to be combined correctly.\n",
    "* Tracks with multiple artists were handled by expanding to a track-artist format and then aggregating artist features.\n",
    "* List-like fields were normalized to avoid issues during merging and aggregation.\n",
    "* Release year was used instead of full dates to avoid adding false precision.\n",
    "* Missing values were minimal in the enriched tracks dataset. About 2% of rows were removed for modeling.\n",
    "* The final enriched dataset is ready for further analysis in a separate notebook.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "anaconda-panel-2023.05-py310",
   "language": "python",
   "name": "conda-env-anaconda-panel-2023.05-py310-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
